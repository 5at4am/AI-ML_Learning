{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0440a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e965b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5802298",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18162fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 20), (200, 20), (800,), (200,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01c6040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.45\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "dummy_modal = [0 for _ in range(len(X_test))]\n",
    "\n",
    "print(dummy_modal)\n",
    "print(accuracy_score(y_test, dummy_modal))\n",
    "print(roc_auc_score(y_test, dummy_modal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce7918af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic logstic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict_proba(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e79015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90a65a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lets focuse on positive outcome \n",
    "model_pred = y_pred[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc54a347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.63724347e-02, 6.40309208e-01, 5.65260417e-01, 8.85628111e-01,\n",
       "       6.13624451e-01, 4.37624521e-01, 9.35901271e-01, 2.55473308e-01,\n",
       "       4.36023942e-02, 3.19186712e-02, 8.86424874e-01, 4.70658450e-01,\n",
       "       8.17920564e-01, 3.06476345e-02, 7.73769429e-01, 4.00833399e-01,\n",
       "       4.02033806e-01, 8.16669768e-03, 3.64054860e-01, 1.27350541e-02,\n",
       "       1.57182369e-02, 9.62752209e-01, 1.81184959e-01, 9.73991503e-01,\n",
       "       9.73378606e-01, 8.45006614e-01, 5.59844910e-01, 5.31972686e-02,\n",
       "       9.21641010e-03, 9.83039677e-01, 9.41017983e-01, 9.16012431e-01,\n",
       "       3.13099219e-02, 9.07979014e-01, 3.60536518e-01, 3.08673499e-01,\n",
       "       2.51320316e-02, 8.80506751e-01, 1.18644098e-01, 8.69652244e-01,\n",
       "       4.94276435e-01, 9.62349398e-01, 5.41652517e-01, 6.29884042e-01,\n",
       "       4.47628210e-01, 8.95430949e-03, 9.64718431e-03, 7.30841409e-01,\n",
       "       4.82913462e-03, 8.08818017e-01, 8.35806427e-01, 9.17851720e-01,\n",
       "       9.53992469e-01, 9.02018820e-01, 2.01050441e-01, 6.41212320e-02,\n",
       "       5.07304470e-01, 9.35949109e-01, 9.80081001e-01, 1.49746825e-01,\n",
       "       3.26413555e-03, 4.14915499e-02, 5.07758401e-01, 2.50433621e-02,\n",
       "       7.95667420e-01, 7.21130661e-01, 1.02031147e-02, 9.95912348e-01,\n",
       "       9.95437974e-01, 2.38063806e-01, 8.71248194e-01, 5.28837511e-01,\n",
       "       3.84399948e-02, 6.07449277e-03, 8.33480111e-01, 9.70659478e-01,\n",
       "       8.15334195e-01, 3.11077664e-01, 4.42135756e-01, 8.05400125e-01,\n",
       "       6.44323904e-01, 8.21987978e-01, 2.83174972e-01, 7.57093183e-01,\n",
       "       7.87238169e-01, 8.95917071e-01, 7.15606409e-01, 4.60476464e-01,\n",
       "       9.83184929e-01, 9.96786256e-01, 9.19827471e-01, 9.65314272e-01,\n",
       "       3.66092161e-01, 1.38193225e-02, 9.95593564e-01, 5.14105306e-02,\n",
       "       1.02860945e-01, 8.11348944e-01, 1.29461804e-01, 1.49385067e-02,\n",
       "       9.96190888e-01, 1.19607591e-01, 9.00631846e-01, 7.98730192e-03,\n",
       "       1.48116667e-02, 2.09254178e-01, 6.43884009e-01, 9.48309672e-02,\n",
       "       9.83375613e-01, 8.11663713e-01, 9.82128483e-01, 8.88188623e-01,\n",
       "       1.27944378e-01, 2.17261737e-02, 5.67922556e-01, 2.44033205e-01,\n",
       "       3.79220688e-01, 8.91323051e-01, 4.30583634e-01, 1.12655081e-02,\n",
       "       2.13071378e-02, 6.23752993e-01, 8.66298655e-01, 8.60742490e-01,\n",
       "       9.13770702e-01, 9.14596783e-01, 7.85831392e-01, 7.36099279e-01,\n",
       "       9.88131032e-01, 7.77037014e-01, 9.44300781e-01, 9.01012496e-01,\n",
       "       9.20589119e-01, 1.19318751e-01, 8.21069650e-01, 9.25758349e-01,\n",
       "       4.74486684e-01, 9.90407451e-01, 3.59329667e-01, 9.91935897e-01,\n",
       "       7.24554088e-01, 9.87739829e-01, 6.73477223e-01, 9.19236524e-01,\n",
       "       2.40356552e-02, 2.42312178e-03, 9.31525475e-02, 4.60803265e-01,\n",
       "       7.34762884e-01, 1.18856178e-02, 9.60299248e-01, 1.99412996e-01,\n",
       "       1.25136487e-01, 3.20387386e-01, 6.13896597e-01, 7.54558432e-04,\n",
       "       8.72649774e-01, 9.99514863e-01, 7.10359135e-01, 4.67753618e-01,\n",
       "       7.97539372e-01, 1.16205926e-01, 2.90306886e-01, 9.97244409e-01,\n",
       "       9.13987760e-01, 4.29287710e-01, 9.97938207e-01, 7.54173341e-02,\n",
       "       9.53882514e-01, 8.83548679e-01, 1.28304020e-01, 9.90890661e-01,\n",
       "       4.60261672e-01, 9.45199861e-01, 5.99032212e-02, 2.38980824e-02,\n",
       "       8.38761436e-01, 1.07240236e-01, 6.01737757e-02, 6.54736402e-01,\n",
       "       9.49697048e-01, 7.68167518e-01, 9.98331479e-01, 9.57828079e-01,\n",
       "       2.36263326e-01, 7.31118106e-01, 2.63721495e-03, 7.79418851e-01,\n",
       "       1.35658752e-01, 9.60494255e-01, 2.35139445e-01, 1.00433782e-01,\n",
       "       3.48314352e-02, 3.89495580e-02, 7.80339780e-04, 4.58619858e-01,\n",
       "       5.24663655e-02, 4.35768575e-02, 9.80192393e-01, 7.10326529e-01])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7fce6de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(roc_auc_score(y_test, y_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Prime\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Prime\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:411\u001b[39m, in \u001b[36maccuracy_score\u001b[39m\u001b[34m(y_true, y_pred, normalize, sample_weight)\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[32m    410\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m y_type, y_true, y_pred, sample_weight = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type.startswith(\u001b[33m\"\u001b[39m\u001b[33mmultilabel\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    416\u001b[39m     differing_labels = _count_nonzero(y_true - y_pred, xp=xp, device=device, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Prime\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:127\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred, sample_weight)\u001b[39m\n\u001b[32m    124\u001b[39m     y_type = {\u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    128\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mClassification metrics can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m targets\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    129\u001b[39m             type_true, type_pred\n\u001b[32m    130\u001b[39m         )\n\u001b[32m    131\u001b[39m     )\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[32m    134\u001b[39m y_type = y_type.pop()\n",
      "\u001b[31mValueError\u001b[39m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcb9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
